{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:28.923944Z",
     "start_time": "2024-02-20T17:10:28.920002Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from curriculum_learning.models.classifier_model import ClassifierModel\n",
    "from curriculum_learning import utils\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "N_TRIALS = 3\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:29.232504Z",
     "start_time": "2024-02-20T17:10:29.223921Z"
    }
   },
   "id": "5ba619241c769e59"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "with open(\"models_hyperparameters.yaml\", \"r\") as stream:\n",
    "    models_hyperparameters = yaml.safe_load(stream)\n",
    "    \n",
    "x, y = utils.load_data(\"../data/cifar-10-batches-py/data_batch_1\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "train_size = x_train.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:29.806142Z",
     "start_time": "2024-02-20T17:10:29.672837Z"
    }
   },
   "id": "869132b068be0fff"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "x_train = np.clip(x_train + np.random.normal(0, 20, x_train.shape), 0, 255)\n",
    "x_val = np.clip(x_val + np.random.normal(0, 20, x_val.shape), 0, 255)\n",
    "x_test = np.clip(x_test + np.random.normal(0, 20, x_test.shape), 0, 255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:32.517675Z",
     "start_time": "2024-02-20T17:10:31.824374Z"
    }
   },
   "id": "81d8245d180ef70f"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# test_models = [\"test_model_1\", \"test_model_2\", \"test_model_3\"]\n",
    "test_models = [\"test_model_1\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:33.089244Z",
     "start_time": "2024-02-20T17:10:33.080929Z"
    }
   },
   "id": "92315aab6b5898bf"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:10:33.622384Z",
     "start_time": "2024-02-20T17:10:33.606096Z"
    }
   },
   "id": "e87e49b3ac1e4e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 938ms/step - loss: 2.7981 - accuracy: 0.0725 - val_loss: 7.5042 - val_accuracy: 0.1380\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 2.6283 - accuracy: 0.1511 - val_loss: 5.7910 - val_accuracy: 0.1460\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.9111 - accuracy: 0.0861 - val_loss: 4.8314 - val_accuracy: 0.1393\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 2.7888 - accuracy: 0.0824 - val_loss: 3.7944 - val_accuracy: 0.1453\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 2.7127 - accuracy: 0.0974 - val_loss: 3.2631 - val_accuracy: 0.1460\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 2.7249 - accuracy: 0.1193 - val_loss: 2.9848 - val_accuracy: 0.1487\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 2.7158 - accuracy: 0.0961 - val_loss: 2.8186 - val_accuracy: 0.1473\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.5636 - accuracy: 0.1237 - val_loss: 2.7236 - val_accuracy: 0.1400\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 2.6244 - accuracy: 0.1274 - val_loss: 2.6721 - val_accuracy: 0.1267\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.5683 - accuracy: 0.1176 - val_loss: 2.6389 - val_accuracy: 0.1153\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 2.5634 - accuracy: 0.1423 - val_loss: 2.6587 - val_accuracy: 0.1100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5851 - accuracy: 0.1198 - val_loss: 2.6872 - val_accuracy: 0.1073\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.4266 - accuracy: 0.1538 - val_loss: 2.6524 - val_accuracy: 0.1180\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.4633 - accuracy: 0.1357 - val_loss: 2.6183 - val_accuracy: 0.1287\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 2.4372 - accuracy: 0.1430 - val_loss: 2.6043 - val_accuracy: 0.1360\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 2.3713 - accuracy: 0.1550 - val_loss: 2.6115 - val_accuracy: 0.1233\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 2.3109 - accuracy: 0.1800 - val_loss: 2.6594 - val_accuracy: 0.1193\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 2.2881 - accuracy: 0.1709 - val_loss: 2.6808 - val_accuracy: 0.1187\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 2.2452 - accuracy: 0.1834 - val_loss: 2.6487 - val_accuracy: 0.1127\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 2.2193 - accuracy: 0.1846 - val_loss: 2.6544 - val_accuracy: 0.1247\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 2.2341 - accuracy: 0.2072 - val_loss: 2.6517 - val_accuracy: 0.1287\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 2.1733 - accuracy: 0.2026 - val_loss: 2.4480 - val_accuracy: 0.1293\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 2.1320 - accuracy: 0.2187 - val_loss: 2.2683 - val_accuracy: 0.1460\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 2.0736 - accuracy: 0.2367 - val_loss: 2.2099 - val_accuracy: 0.1647\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 2.0768 - accuracy: 0.2363 - val_loss: 2.2388 - val_accuracy: 0.1727\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 2.0552 - accuracy: 0.2494 - val_loss: 2.3556 - val_accuracy: 0.1740\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.0541 - accuracy: 0.2515 - val_loss: 2.2832 - val_accuracy: 0.1900\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 2.0120 - accuracy: 0.2602 - val_loss: 2.1654 - val_accuracy: 0.2047\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 1.9933 - accuracy: 0.2563 - val_loss: 2.0792 - val_accuracy: 0.2253\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 1.9821 - accuracy: 0.2795 - val_loss: 2.0329 - val_accuracy: 0.2447\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1.9731 - accuracy: 0.2715 - val_loss: 1.9783 - val_accuracy: 0.2547\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1.9109 - accuracy: 0.2996 - val_loss: 1.9849 - val_accuracy: 0.2600\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1.9468 - accuracy: 0.2782 - val_loss: 1.9725 - val_accuracy: 0.2673\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1.9262 - accuracy: 0.2862 - val_loss: 1.9202 - val_accuracy: 0.3020\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 1.8950 - accuracy: 0.2948 - val_loss: 1.9405 - val_accuracy: 0.2967\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.8930 - accuracy: 0.2926 - val_loss: 1.8287 - val_accuracy: 0.3140\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1.8457 - accuracy: 0.3165 - val_loss: 1.7584 - val_accuracy: 0.3447\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 1.8668 - accuracy: 0.3168 - val_loss: 1.7567 - val_accuracy: 0.3487\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 1.8189 - accuracy: 0.3359 - val_loss: 1.7388 - val_accuracy: 0.3513\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 1.8184 - accuracy: 0.3336 - val_loss: 1.8007 - val_accuracy: 0.3380\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 1.8492 - accuracy: 0.3104 - val_loss: 1.6949 - val_accuracy: 0.3687\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 1.8061 - accuracy: 0.3427 - val_loss: 1.6677 - val_accuracy: 0.3807\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.7884 - accuracy: 0.3401 - val_loss: 1.6644 - val_accuracy: 0.3860\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.7689 - accuracy: 0.3592 - val_loss: 1.6434 - val_accuracy: 0.3920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.7312 - accuracy: 0.3569 - val_loss: 1.7804 - val_accuracy: 0.3493\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7552 - accuracy: 0.3505 - val_loss: 1.6750 - val_accuracy: 0.3813\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.7224 - accuracy: 0.3609 - val_loss: 1.6227 - val_accuracy: 0.3933\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.7126 - accuracy: 0.3583 - val_loss: 1.6492 - val_accuracy: 0.3867\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1.7151 - accuracy: 0.3655 - val_loss: 1.6739 - val_accuracy: 0.3867\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1.6932 - accuracy: 0.3797 - val_loss: 1.6128 - val_accuracy: 0.4073\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1.6617 - accuracy: 0.3782 - val_loss: 1.5976 - val_accuracy: 0.4100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6686 - accuracy: 0.3778 - val_loss: 1.5869 - val_accuracy: 0.4053\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.6509 - accuracy: 0.3786 - val_loss: 1.6645 - val_accuracy: 0.3760\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.6616 - accuracy: 0.3881 - val_loss: 1.5989 - val_accuracy: 0.4133\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.6510 - accuracy: 0.3805 - val_loss: 1.5632 - val_accuracy: 0.4180\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.6379 - accuracy: 0.3885 - val_loss: 1.5869 - val_accuracy: 0.4180\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 1.6399 - accuracy: 0.3843 - val_loss: 1.5666 - val_accuracy: 0.4253\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 1.6338 - accuracy: 0.3945 - val_loss: 1.6238 - val_accuracy: 0.4067\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 1.6263 - accuracy: 0.4058 - val_loss: 1.5585 - val_accuracy: 0.4300\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 1.6062 - accuracy: 0.4046 - val_loss: 1.5638 - val_accuracy: 0.4320\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 1.5683 - accuracy: 0.4175 - val_loss: 1.6454 - val_accuracy: 0.4107\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.5739 - accuracy: 0.4166 - val_loss: 1.5187 - val_accuracy: 0.4473\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.5779 - accuracy: 0.4160 - val_loss: 1.5712 - val_accuracy: 0.4253\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.5687 - accuracy: 0.4188 - val_loss: 1.4831 - val_accuracy: 0.4540\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.5616 - accuracy: 0.4204 - val_loss: 1.5185 - val_accuracy: 0.4440\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.5562 - accuracy: 0.4313 - val_loss: 1.4916 - val_accuracy: 0.4580\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.5488 - accuracy: 0.4348 - val_loss: 1.5032 - val_accuracy: 0.4620\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 1.5325 - accuracy: 0.4401 - val_loss: 1.4577 - val_accuracy: 0.4713\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 1.5254 - accuracy: 0.4449 - val_loss: 1.5253 - val_accuracy: 0.4413\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 1.5267 - accuracy: 0.4383 - val_loss: 1.5445 - val_accuracy: 0.4500\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 1.4981 - accuracy: 0.4485 - val_loss: 1.5228 - val_accuracy: 0.4453\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 1.4857 - accuracy: 0.4472 - val_loss: 1.4474 - val_accuracy: 0.4760\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 1.4946 - accuracy: 0.4426 - val_loss: 1.4789 - val_accuracy: 0.4707\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 1.5014 - accuracy: 0.4498 - val_loss: 1.6256 - val_accuracy: 0.4253\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 1.4709 - accuracy: 0.4530 - val_loss: 1.4211 - val_accuracy: 0.4893\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 1.4623 - accuracy: 0.4658 - val_loss: 1.5291 - val_accuracy: 0.4500\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 1.4643 - accuracy: 0.4605 - val_loss: 1.3896 - val_accuracy: 0.5047\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 1.4494 - accuracy: 0.4652 - val_loss: 1.3938 - val_accuracy: 0.5040\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 1.4652 - accuracy: 0.4581 - val_loss: 1.4893 - val_accuracy: 0.4640\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.4402 - accuracy: 0.4682 - val_loss: 1.3824 - val_accuracy: 0.4880\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.4339 - accuracy: 0.4756 - val_loss: 1.3827 - val_accuracy: 0.4953\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.4212 - accuracy: 0.4792 - val_loss: 1.3814 - val_accuracy: 0.5053\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 1.4265 - accuracy: 0.4762 - val_loss: 1.3672 - val_accuracy: 0.5093\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 1.4145 - accuracy: 0.4815 - val_loss: 1.4505 - val_accuracy: 0.4740\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 1.3947 - accuracy: 0.4817 - val_loss: 1.3783 - val_accuracy: 0.5027\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 1.4040 - accuracy: 0.4919 - val_loss: 1.3442 - val_accuracy: 0.5100\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 1.3942 - accuracy: 0.4842 - val_loss: 1.4023 - val_accuracy: 0.4867\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 1.3835 - accuracy: 0.4905 - val_loss: 1.6270 - val_accuracy: 0.4393\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 1.3781 - accuracy: 0.4957 - val_loss: 1.4626 - val_accuracy: 0.4767\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 1.3729 - accuracy: 0.5014 - val_loss: 1.3729 - val_accuracy: 0.5007\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 1.3653 - accuracy: 0.5074 - val_loss: 1.3423 - val_accuracy: 0.5087\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 1.3439 - accuracy: 0.5023 - val_loss: 1.3605 - val_accuracy: 0.5027\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 1.3492 - accuracy: 0.5006 - val_loss: 1.3295 - val_accuracy: 0.5173\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.3314 - accuracy: 0.5095 - val_loss: 1.3938 - val_accuracy: 0.4967\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 1.3406 - accuracy: 0.5156 - val_loss: 1.3838 - val_accuracy: 0.5080\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.3359 - accuracy: 0.5149 - val_loss: 1.3464 - val_accuracy: 0.5093\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.3345 - accuracy: 0.5122 - val_loss: 1.4472 - val_accuracy: 0.4873\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 1.3119 - accuracy: 0.5155 - val_loss: 1.3645 - val_accuracy: 0.5127\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.3097 - accuracy: 0.5227 - val_loss: 1.3365 - val_accuracy: 0.5120\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.3237 - accuracy: 0.5200 - val_loss: 1.3037 - val_accuracy: 0.5193\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.3049 - accuracy: 0.5185 - val_loss: 1.3966 - val_accuracy: 0.5027\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 1.2911 - accuracy: 0.5302 - val_loss: 1.3169 - val_accuracy: 0.5207\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 1.2853 - accuracy: 0.5324 - val_loss: 1.2890 - val_accuracy: 0.5380\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 1.2878 - accuracy: 0.5308 - val_loss: 1.3004 - val_accuracy: 0.5340\n",
      "22/22 [==============================] - 1s 50ms/step - loss: 1.2895 - accuracy: 0.5260 - val_loss: 1.3029 - val_accuracy: 0.5207\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 1.2957 - accuracy: 0.5245 - val_loss: 1.3402 - val_accuracy: 0.5267\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 1.2628 - accuracy: 0.5393 - val_loss: 1.2969 - val_accuracy: 0.5347\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 1.2529 - accuracy: 0.5394 - val_loss: 1.3157 - val_accuracy: 0.5287\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 1.2678 - accuracy: 0.5375 - val_loss: 1.2753 - val_accuracy: 0.5500\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 1.2489 - accuracy: 0.5360 - val_loss: 1.2950 - val_accuracy: 0.5427\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 1.2250 - accuracy: 0.5476 - val_loss: 1.2552 - val_accuracy: 0.5433\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 1.2422 - accuracy: 0.5494 - val_loss: 1.2770 - val_accuracy: 0.5407\n",
      "23/23 [==============================] - 1s 49ms/step - loss: 1.2310 - accuracy: 0.5556 - val_loss: 1.3916 - val_accuracy: 0.5187\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.2432 - accuracy: 0.5396 - val_loss: 1.3110 - val_accuracy: 0.5273\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 1.2341 - accuracy: 0.5557 - val_loss: 1.2652 - val_accuracy: 0.5480\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 1.2209 - accuracy: 0.5565 - val_loss: 1.3480 - val_accuracy: 0.5193\n",
      "23/23 [==============================] - 1s 50ms/step - loss: 1.2115 - accuracy: 0.5524 - val_loss: 1.3518 - val_accuracy: 0.5187\n",
      "23/23 [==============================] - 1s 50ms/step - loss: 1.2118 - accuracy: 0.5616 - val_loss: 1.3042 - val_accuracy: 0.5240\n",
      "23/23 [==============================] - 1s 49ms/step - loss: 1.2162 - accuracy: 0.5507 - val_loss: 1.3543 - val_accuracy: 0.5267\n",
      "23/23 [==============================] - 1s 49ms/step - loss: 1.2028 - accuracy: 0.5614 - val_loss: 1.2663 - val_accuracy: 0.5487\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 1.1906 - accuracy: 0.5680 - val_loss: 1.2793 - val_accuracy: 0.5327\n",
      "23/23 [==============================] - 1s 49ms/step - loss: 1.1890 - accuracy: 0.5647 - val_loss: 1.2629 - val_accuracy: 0.5473\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 1.1900 - accuracy: 0.5685 - val_loss: 1.3054 - val_accuracy: 0.5360\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 1.2149 - accuracy: 0.5487 - val_loss: 1.3903 - val_accuracy: 0.5033\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 1.1827 - accuracy: 0.5723 - val_loss: 1.3933 - val_accuracy: 0.5053\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 1.1729 - accuracy: 0.5664 - val_loss: 1.3091 - val_accuracy: 0.5380\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 1.1563 - accuracy: 0.5776 - val_loss: 1.2654 - val_accuracy: 0.5527\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 1.1692 - accuracy: 0.5743 - val_loss: 1.3259 - val_accuracy: 0.5280\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 1.1724 - accuracy: 0.5744 - val_loss: 1.3367 - val_accuracy: 0.5193\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 1.1379 - accuracy: 0.5870 - val_loss: 1.2378 - val_accuracy: 0.5587\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 1.1501 - accuracy: 0.5824 - val_loss: 1.2561 - val_accuracy: 0.5633\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 1.1372 - accuracy: 0.5820 - val_loss: 1.3202 - val_accuracy: 0.5240\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 1.1481 - accuracy: 0.5827 - val_loss: 1.2385 - val_accuracy: 0.5647\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 1.1440 - accuracy: 0.5871 - val_loss: 1.3533 - val_accuracy: 0.5333\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 1.1265 - accuracy: 0.5883 - val_loss: 1.2413 - val_accuracy: 0.5620\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 1.1247 - accuracy: 0.5849 - val_loss: 1.2741 - val_accuracy: 0.5553\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 1.1260 - accuracy: 0.5928 - val_loss: 1.2482 - val_accuracy: 0.5600\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 1.1320 - accuracy: 0.5921 - val_loss: 1.2418 - val_accuracy: 0.5553\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 1.1235 - accuracy: 0.5933 - val_loss: 1.2748 - val_accuracy: 0.5507\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 1.1269 - accuracy: 0.5872 - val_loss: 1.2479 - val_accuracy: 0.5580\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 1.1109 - accuracy: 0.6043 - val_loss: 1.2357 - val_accuracy: 0.5640\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 1.1103 - accuracy: 0.5992 - val_loss: 1.2255 - val_accuracy: 0.5613\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 1.0981 - accuracy: 0.6039 - val_loss: 1.2441 - val_accuracy: 0.5533\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 1.0819 - accuracy: 0.6098 - val_loss: 1.2742 - val_accuracy: 0.5447\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 1.1049 - accuracy: 0.5999 - val_loss: 1.2179 - val_accuracy: 0.5660\n",
      " 1/25 [>.............................] - ETA: 1s - loss: 1.0964 - accuracy: 0.5820"
     ]
    }
   ],
   "source": [
    "for test_model in test_models:\n",
    "    print(test_model)\n",
    "    model_scores = []\n",
    "\n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model = ClassifierModel(output_shape=10, **models_hyperparameters[test_model])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "        \n",
    "        for i in range(N_EPOCHS):\n",
    "            n_samples = int(np.tanh(2 * (i + 1)/ N_EPOCHS) * train_size)\n",
    "            samples_ids = np.random.choice(range(train_size), n_samples, replace=False)\n",
    "\n",
    "            model.fit(\n",
    "                x_train[samples_ids], y_train[samples_ids], \n",
    "                validation_data=(x_val, y_val),\n",
    "                epochs=1, batch_size=BATCH_SIZE,\n",
    "                verbose=1, callbacks=[early_stopping]\n",
    "            )\n",
    "        \n",
    "        _, accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "        \n",
    "        model_scores.append(accuracy)\n",
    "\n",
    "    results[test_model] = model_scores"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-20T17:10:34.233707Z"
    }
   },
   "id": "db6359a77869578b"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "{'test_model_1': [0.49142858386039734, 0.5022857189178467, 0.5157142877578735]}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:48:44.946374Z",
     "start_time": "2024-02-20T16:48:44.939762Z"
    }
   },
   "id": "b42fa9a082067602"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e42d618947400d47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
