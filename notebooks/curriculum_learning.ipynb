{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from curriculum_learning.models.classifier_model import ClassifierModel\n",
    "from curriculum_learning import utils\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATASET_NAME = \"eurosat\"\n",
    "\n",
    "N_EPOCHS_CL = 50\n",
    "N_TRIALS = 50\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "model_fit_base_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "model_fit_1_params = model_fit_base_params | {\"epochs\": 1}\n",
    "model_fit_500_params = model_fit_base_params | {\"epochs\": 500}\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5080a937fd234104",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "ds_1 = tfds.load(DATASET_NAME, split=\"train\", as_supervised=True, shuffle_files=False)\n",
    "for x_, y_ in ds_1.as_numpy_iterator():\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "    \n",
    "# ds_2 = tfds.load(DATASET_NAME, split=\"test\", as_supervised=True, shuffle_files=False)\n",
    "# for x_, y_ in ds_2.as_numpy_iterator():\n",
    "#     x.append(x_)\n",
    "#     y.append(y_)\n",
    "\n",
    "x = np.array(x, dtype=np.float32) / 255\n",
    "y = np.array(y, dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833df77eba9d27a2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "train_size = x_train.shape[0]\n",
    "\n",
    "x_train_sorted = x_train[np.argsort(y_train)]\n",
    "y_train_sorted = y_train[np.argsort(y_train)]\n",
    "_, counts = np.unique(y_train_sorted, return_counts=True)\n",
    "\n",
    "train_size, len(x_val), len(x_test), train_size + len(x_val) + len(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8424e92d91deb0ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ClassifierModel(output_shape=n_classes, **utils.MODEL_ARCHITECTURE)\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "model(x_train[0:1])\n",
    "model.load_weights(f\"../models/default_model_weights_{DATASET_NAME}.weights.h5\")\n",
    "model_weights = model.get_weights()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d8c20ae81a03a89",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_experiments(value_type: str, order_type: utils.OrderType, name: str):\n",
    "    best_model_weights = model.get_weights()\n",
    "    acc = []\n",
    "    \n",
    "    re_ma = []\n",
    "    re_wg = []\n",
    "    \n",
    "    pr_ma = []\n",
    "    pr_wg = []\n",
    "    \n",
    "    f1_ma = []\n",
    "    f1_wg = []\n",
    "    \n",
    "    if value_type == \"edges\":\n",
    "        samples_values = utils.calculate_values_edges(x_train_sorted, blur=True)\n",
    "        samples_proba = utils.normalize_values_per_group(samples_values, counts)\n",
    "    \n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model.set_weights(model_weights)\n",
    "    \n",
    "        for i in range(N_EPOCHS_CL):\n",
    "            n_samples = int(np.tanh(4 * (i + 1) / N_EPOCHS_CL) * train_size)\n",
    "\n",
    "            if value_type == \"losses\":\n",
    "                samples_values = utils.calculate_values_losses(model, x_train_sorted, y_train_sorted, batch_size=BATCH_SIZE)\n",
    "                samples_proba = utils.normalize_values_per_group(samples_values, counts)\n",
    "\n",
    "            samples_ids = utils.chose_samples(n_samples, samples_proba, order_type)\n",
    "    \n",
    "            model.fit(x_train_sorted[samples_ids], y_train_sorted[samples_ids], **model_fit_1_params)\n",
    "    \n",
    "        model.fit(\n",
    "            x_train_sorted, y_train_sorted, validation_data=(x_val, y_val), **model_fit_500_params,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=10)]\n",
    "        )\n",
    "              \n",
    "        y_pred = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=0), axis=1)  \n",
    "        utils.calculate_metrics(y_test, y_pred, acc, re_ma, re_wg, pr_ma, pr_wg, f1_ma, f1_wg)\n",
    "        if acc[-1] >= max(acc):\n",
    "            best_model_weights = model.get_weights()\n",
    "            \n",
    "        print(f\"Mean accuracy: {np.mean(acc):.4f}, Current accuracy: {acc[-1]:.4f}\")\n",
    "        \n",
    "    df_scores = utils.create_df_scores(acc, re_ma, re_wg, pr_ma, pr_wg, f1_ma, f1_wg)\n",
    "    df_scores.to_csv(f\"../data/results/{name}.csv\")\n",
    "    \n",
    "    model.set_weights(best_model_weights)\n",
    "    model.save_weights(f\"../models/best/{name}.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe67648b5f902c5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Edges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dbc5faac813bf81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vals = \"edges\"\n",
    "ot = utils.OrderType.PROBA\n",
    "run_experiments(vals, ot, name=f\"{vals}_{ot.value}_{DATASET_NAME}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdf560a64be5b55e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vals = \"edges\"\n",
    "ot = utils.OrderType.FIXED\n",
    "run_experiments(vals, ot, name=f\"{vals}_{ot.value}_{DATASET_NAME}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5a8bf1cf4005b9b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8f1dcdeeba8b74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.load_weights(f\"../models/best/edges_fixed_eurosat.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "623422feb3b84d3a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "648a7da0f66bf140",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vals = \"losses\"\n",
    "ot = utils.OrderType.PROBA\n",
    "run_experiments(vals, ot, name=f\"{vals}_{ot.value}_{DATASET_NAME}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fab4095ceccdac7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vals = \"losses\"\n",
    "ot = utils.OrderType.FIXED\n",
    "run_experiments(vals, ot, name=f\"{vals}_{ot.value}_{DATASET_NAME}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd364836f49f5035"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75688d36e3c5d82c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_experiments_random(name: str):    \n",
    "    best_model_weights = model.get_weights()\n",
    "    acc = []\n",
    "    \n",
    "    re_ma = []\n",
    "    re_wg = []\n",
    "    \n",
    "    pr_ma = []\n",
    "    pr_wg = []\n",
    "    \n",
    "    f1_ma = []\n",
    "    f1_wg = []\n",
    "    \n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model.set_weights(model_weights)\n",
    "    \n",
    "        model.fit(\n",
    "            x_train_sorted, y_train_sorted, validation_data=(x_val, y_val), **model_fit_500_params,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=35)]\n",
    "        )\n",
    "    \n",
    "        y_pred = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=0), axis=1)  \n",
    "        utils.calculate_metrics(y_test, y_pred, acc, re_ma, re_wg, pr_ma, pr_wg, f1_ma, f1_wg)\n",
    "        if acc[-1] > max(acc):\n",
    "            best_model_weights = model.get_weights()\n",
    "            \n",
    "        print(f\"Mean accuracy: {np.mean(acc):.4f}, Current accuracy: {acc[-1]:.4f}\")\n",
    "        \n",
    "    df_scores = utils.create_df_scores(acc, re_ma, re_wg, pr_ma, pr_wg, f1_ma, f1_wg)\n",
    "    df_scores.to_csv(f\"../data/results/{name}.csv\")\n",
    "\n",
    "    model.set_weights(best_model_weights)\n",
    "    model.save_weights(f\"../models/best/{name}.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4944c9f8eaffaf6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_experiments_random(name=f\"random_{DATASET_NAME}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "435948d951668730",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57dd8db805ba08cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
