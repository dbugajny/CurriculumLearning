{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from curriculum_learning.models.classifier_model import ClassifierModel\n",
    "from curriculum_learning import utils\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_ARCHITECTURE = {\n",
    "    'conv_block_filters': [16, 32, 64],\n",
    "    'conv_block_kernel_sizes': [3, 3, 3],\n",
    "    'conv_block_strides': [2, 2, 2],\n",
    "    'conv_block_dropout_rates': [0.2, 0.2, 0.2],\n",
    "    'dense_block_units': [32],\n",
    "    'dense_block_dropout_rates': [0.5]\n",
    "}\n",
    "\n",
    "N_EPOCHS = 50\n",
    "N_TRIALS = 50\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T16:23:26.925523Z",
     "start_time": "2024-07-16T16:23:26.920396Z"
    }
   },
   "id": "5080a937fd234104",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "ds_1 = tfds.load(\"stl10\", split=\"train\", as_supervised=True, shuffle_files=False)\n",
    "for x_, y_ in ds_1.as_numpy_iterator():\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "    \n",
    "ds_2 = tfds.load(\"stl10\", split=\"test\", as_supervised=True, shuffle_files=False)\n",
    "for x_, y_ in ds_2.as_numpy_iterator():\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "\n",
    "x = np.array(x, dtype=np.float32) / 255\n",
    "y = np.array(y, dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833df77eba9d27a2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.95, random_state=42, stratify=y)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "train_size = x_train.shape[0]\n",
    "train_size, len(x_val), len(x_test), train_size + len(x_val) + len(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8424e92d91deb0ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train_sorted = x_train[np.argsort(y_train)]\n",
    "y_train_sorted = y_train[np.argsort(y_train)]\n",
    "_, counts = np.unique(y_train_sorted, return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2cd5df2d1ace314",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ClassifierModel(output_shape=n_classes, **MODEL_ARCHITECTURE)\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "model(x_train[0:1])\n",
    "model.load_weights(\"../models/default_model_weights_stl10.weights.h5\")\n",
    "model_weights = model.get_weights()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d8c20ae81a03a89",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def validate_name(value_type: str, order_type: utils.OrderType, name: str):\n",
    "    assert name.startswith(f\"{value_type}_{order_type}_\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T16:22:53.457598Z",
     "start_time": "2024-07-16T16:22:53.453770Z"
    }
   },
   "id": "9857542122598cad",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_fit_1_params = {\n",
    "    \"epochs\": N_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "model_fit_2_params = {\n",
    "    \"epochs\": 500,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"verbose\": 0,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8ac2a9fabc88b66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_experiments(value_type: str, order_type: utils.OrderType, name: str):\n",
    "    validate_name(value_type, order_type, name)\n",
    "    acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma = [], [], [], [], [], [], []\n",
    "    best_model_weights = model.get_weights()\n",
    "    \n",
    "    if value_type == \"edges\":\n",
    "        samples_values = utils.calculate_values_edges(x_train_sorted, blur=True)\n",
    "        samples_proba = utils.normalize_values_per_group(samples_values, counts)\n",
    "    \n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model.set_weights(model_weights)\n",
    "    \n",
    "        for i in range(N_EPOCHS):\n",
    "            n_samples = int(np.tanh(4 * (i + 1) / N_EPOCHS) * train_size)\n",
    "\n",
    "            if value_type == \"losses\":\n",
    "                samples_values = utils.calculate_values_losses(model, x_train_sorted, y_train_sorted, batch_size=BATCH_SIZE)\n",
    "                samples_proba = utils.normalize_values_per_group(samples_values, counts)\n",
    "\n",
    "            samples_ids = utils.chose_samples(n_samples, samples_proba, order_type)\n",
    "    \n",
    "            model.fit(x_train_sorted[samples_ids], y_train_sorted[samples_ids], **model_fit_1_params)\n",
    "    \n",
    "        model.fit(\n",
    "            x_train_sorted, y_train_sorted, validation_data=(x_val, y_val), **model_fit_2_params,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=10)]\n",
    "        )\n",
    "              \n",
    "        y_pred = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=0), axis=1)  \n",
    "        utils.calculate_metrics(y_test, y_pred, acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma)\n",
    "        if acc[-1] > max(acc):\n",
    "            best_model_weights = model.get_weights()\n",
    "            \n",
    "        print(f\"Mean accuracy: {np.mean(acc):.4f}, Current accuracy: {acc[-1]:.4f}\")\n",
    "        \n",
    "    df_scores = utils.create_df_scores(acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma)\n",
    "    df_scores.to_csv(f\"../data/results/{name}.csv\")\n",
    "    \n",
    "    model.set_weights(best_model_weights)\n",
    "    model.save_weights(f\"../models/best/{name}.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T16:23:07.128457Z",
     "start_time": "2024-07-16T16:23:07.120698Z"
    }
   },
   "id": "efe67648b5f902c5",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Edges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dbc5faac813bf81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_experiments(\"edges\", utils.OrderType.PROBA, name=\"edges_proba_stl10\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdf560a64be5b55e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_experiments(\"edges\", utils.OrderType.FIXED, name=\"edges_fixed_stl10\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5a8bf1cf4005b9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8f1dcdeeba8b74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_experiments(\"losses\", utils.OrderType.PROBA, name=\"losses_proba_stl10\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fab4095ceccdac7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_experiments(\"losses\", utils.OrderType.FIXED, name=\"losses_fixed_stl10\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd364836f49f5035"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75688d36e3c5d82c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_fit_3_params = {\n",
    "    \"epochs\": 500,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"verbose\": 0,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "581f100311870af3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_experiments_random(name: str):    \n",
    "    acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma = [], [], [], [], [], [], []\n",
    "    best_model_weights = model.get_weights()\n",
    "    \n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model.set_weights(model_weights)\n",
    "    \n",
    "        model.fit(\n",
    "            x_train_sorted, y_train_sorted, validation_data=(x_val, y_val), **model_fit_3_params,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=35)]\n",
    "        )\n",
    "    \n",
    "        y_pred = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=0), axis=1)  \n",
    "        utils.calculate_metrics(y_test, y_pred, acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma)\n",
    "        if acc[-1] > max(acc):\n",
    "            best_model_weights = model.get_weights()\n",
    "            \n",
    "        print(f\"Mean accuracy: {np.mean(acc):.4f}, Current accuracy: {acc[-1]:.4f}\")\n",
    "        \n",
    "    df_scores = utils.create_df_scores(acc, re_mi, re_ma, pr_mi, pr_ma, f1_mi, f1_ma)\n",
    "    df_scores.to_csv(f\"../data/results/{name}.csv\")\n",
    "\n",
    "    model.set_weights(best_model_weights)\n",
    "    model.save_weights(f\"../models/best/{name}.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4944c9f8eaffaf6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# with open('RANDOM.txt', 'w') as f:\n",
    "#     for score in model_scores_random:\n",
    "#         f.write(f\"{score}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c66f23119e6fd335",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model_scores_random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2671c41f0227ac0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# my_dict = {\n",
    "#     'model_scores_random': model_scores_random,\n",
    "#     'model_scores_proba_edges': model_scores_proba_edges,\n",
    "#     'model_scores_fixed_edges': model_scores_fixed_edges,\n",
    "#     'model_scores_proba_loss': model_scores_proba_loss,\n",
    "#     'model_scores_fixed_loss': model_scores_fixed_loss,\n",
    "# }\n",
    "# \n",
    "# fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# ax.boxplot(my_dict.values())\n",
    "# ax.set_xticklabels(my_dict.keys())\n",
    "# plt.ylim([0.725, 0.865])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5233365e21fbd13d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "435948d951668730",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
