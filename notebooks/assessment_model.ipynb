{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:25:34.204021Z",
     "start_time": "2024-02-20T17:25:34.198977Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from curriculum_learning.models.classifier_model import ClassifierModel\n",
    "from curriculum_learning import utils\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "N_TRIALS = 3\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:33:42.695125Z",
     "start_time": "2024-02-20T17:33:42.691495Z"
    }
   },
   "id": "bab2c3f4ef4cf399"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "with open(\"models_hyperparameters.yaml\", \"r\") as stream:\n",
    "    models_hyperparameters = yaml.safe_load(stream)\n",
    "    \n",
    "x, y = utils.load_data(\"../data/cifar-10-batches-py/data_batch_1\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "train_size = x_train.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:34:21.014128Z",
     "start_time": "2024-02-20T17:34:20.875664Z"
    }
   },
   "id": "8424e92d91deb0ac"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "x_train = np.clip(x_train + np.random.normal(0, 40, x_train.shape), 0, 255)\n",
    "x_val = np.clip(x_val + np.random.normal(0, 40, x_val.shape), 0, 255)\n",
    "x_test = np.clip(x_test + np.random.normal(0, 40, x_test.shape), 0, 255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:34:22.413632Z",
     "start_time": "2024-02-20T17:34:21.694285Z"
    }
   },
   "id": "7610b74207fb2df0"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 2.5757 - accuracy: 0.1180\n",
      "Epoch 2/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.3181 - accuracy: 0.1704\n",
      "Epoch 3/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.1645 - accuracy: 0.2104\n",
      "Epoch 4/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.0815 - accuracy: 0.2423\n",
      "Epoch 5/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.0188 - accuracy: 0.2609\n",
      "Epoch 6/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.9558 - accuracy: 0.2744\n",
      "Epoch 7/60\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.8975 - accuracy: 0.3097\n",
      "Epoch 8/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.8552 - accuracy: 0.3091\n",
      "Epoch 9/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.8165 - accuracy: 0.3320\n",
      "Epoch 10/60\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.7789 - accuracy: 0.3429\n",
      "Epoch 11/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.7505 - accuracy: 0.3474\n",
      "Epoch 12/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.7454 - accuracy: 0.3536\n",
      "Epoch 13/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.6938 - accuracy: 0.3669\n",
      "Epoch 14/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.6808 - accuracy: 0.3717\n",
      "Epoch 15/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.6665 - accuracy: 0.3859\n",
      "Epoch 16/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.6499 - accuracy: 0.3953\n",
      "Epoch 17/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.6304 - accuracy: 0.3950\n",
      "Epoch 18/60\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.6158 - accuracy: 0.4003\n",
      "Epoch 19/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.5903 - accuracy: 0.4177\n",
      "Epoch 20/60\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5792 - accuracy: 0.4184\n",
      "Epoch 21/60\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5652 - accuracy: 0.4214\n",
      "Epoch 22/60\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.5556 - accuracy: 0.4246\n",
      "Epoch 23/60\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.5355 - accuracy: 0.4331\n",
      "Epoch 24/60\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5128 - accuracy: 0.4336\n",
      "Epoch 25/60\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.5080 - accuracy: 0.4374\n",
      "Epoch 26/60\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.4984 - accuracy: 0.4509\n",
      "Epoch 27/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4890 - accuracy: 0.4544\n",
      "Epoch 28/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.4641 - accuracy: 0.4626\n",
      "Epoch 29/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.4555 - accuracy: 0.4601\n",
      "Epoch 30/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4530 - accuracy: 0.4613\n",
      "Epoch 31/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.4447 - accuracy: 0.4653\n",
      "Epoch 32/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4245 - accuracy: 0.4759\n",
      "Epoch 33/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.4206 - accuracy: 0.4774\n",
      "Epoch 34/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.4140 - accuracy: 0.4813\n",
      "Epoch 35/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4152 - accuracy: 0.4819\n",
      "Epoch 36/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3905 - accuracy: 0.4833\n",
      "Epoch 37/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3979 - accuracy: 0.4790\n",
      "Epoch 38/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3708 - accuracy: 0.4896\n",
      "Epoch 39/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.3598 - accuracy: 0.5033\n",
      "Epoch 40/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.3732 - accuracy: 0.4916\n",
      "Epoch 41/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3658 - accuracy: 0.5003\n",
      "Epoch 42/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3499 - accuracy: 0.4953\n",
      "Epoch 43/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3406 - accuracy: 0.5061\n",
      "Epoch 44/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3286 - accuracy: 0.5109\n",
      "Epoch 45/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3316 - accuracy: 0.5087\n",
      "Epoch 46/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.3364 - accuracy: 0.5076\n",
      "Epoch 47/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3252 - accuracy: 0.5103\n",
      "Epoch 48/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2983 - accuracy: 0.5259\n",
      "Epoch 49/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.3046 - accuracy: 0.5229\n",
      "Epoch 50/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2825 - accuracy: 0.5257\n",
      "Epoch 51/60\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.2807 - accuracy: 0.5273\n",
      "Epoch 52/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2740 - accuracy: 0.5296\n",
      "Epoch 53/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2764 - accuracy: 0.5304\n",
      "Epoch 54/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2615 - accuracy: 0.5380\n",
      "Epoch 55/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2674 - accuracy: 0.5436\n",
      "Epoch 56/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2469 - accuracy: 0.5321\n",
      "Epoch 57/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2287 - accuracy: 0.5486\n",
      "Epoch 58/60\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2360 - accuracy: 0.5411\n",
      "Epoch 59/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2450 - accuracy: 0.5357\n",
      "Epoch 60/60\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2188 - accuracy: 0.5516\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x31feaee00>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessment_model = ClassifierModel(output_shape=10, **models_hyperparameters[\"assessment_model\"])\n",
    "\n",
    "assessment_model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "        \n",
    "assessment_model.fit(x_train, y_train, epochs=60, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:35:17.193471Z",
     "start_time": "2024-02-20T17:34:27.980810Z"
    }
   },
   "id": "bdafb8a9c136f286"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "y_pred_assessment = assessment_model.predict(x_train, verbose=0)\n",
    "\n",
    "losses_assessment = utils.calculate_loss_per_sample(y_train, y_pred_assessment, loss)\n",
    "order_assessment = np.argsort(losses_assessment)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:35:21.896922Z",
     "start_time": "2024-02-20T17:35:17.179122Z"
    }
   },
   "id": "b6b8d2b35609d828"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# test_models = [\"test_model_1\", \"test_model_2\", \"test_model_3\"]\n",
    "test_models = [\"test_model_1\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:36:18.758573Z",
     "start_time": "2024-02-20T17:36:18.752486Z"
    }
   },
   "id": "fe21ef1466862a11"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:36:19.009617Z",
     "start_time": "2024-02-20T17:36:19.002653Z"
    }
   },
   "id": "d38ab788eb08c9f4"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 142ms/step - loss: 2.6902 - accuracy: 0.1254 - val_loss: 6.2561 - val_accuracy: 0.0840\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.4531 - accuracy: 0.1470 - val_loss: 6.2057 - val_accuracy: 0.0793\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.2640 - accuracy: 0.1880 - val_loss: 8.9866 - val_accuracy: 0.0927\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.1082 - accuracy: 0.2360 - val_loss: 12.6921 - val_accuracy: 0.0927\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.9385 - accuracy: 0.3295 - val_loss: 15.3668 - val_accuracy: 0.0927\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 1.8198 - accuracy: 0.3586 - val_loss: 15.1879 - val_accuracy: 0.0927\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1.7156 - accuracy: 0.4173 - val_loss: 13.0719 - val_accuracy: 0.0933\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.6616 - accuracy: 0.4474 - val_loss: 9.0210 - val_accuracy: 0.0993\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 1.6154 - accuracy: 0.4425 - val_loss: 5.4535 - val_accuracy: 0.1180\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 1.5825 - accuracy: 0.4663 - val_loss: 3.7788 - val_accuracy: 0.1487\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.5600 - accuracy: 0.4608 - val_loss: 2.9008 - val_accuracy: 0.1893\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1.5473 - accuracy: 0.4941 - val_loss: 2.4496 - val_accuracy: 0.2313\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 1.5253 - accuracy: 0.4987 - val_loss: 2.2128 - val_accuracy: 0.2693\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.5255 - accuracy: 0.4911 - val_loss: 2.1520 - val_accuracy: 0.2833\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 1.5258 - accuracy: 0.4852 - val_loss: 2.1260 - val_accuracy: 0.3027\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.5005 - accuracy: 0.4911 - val_loss: 2.1507 - val_accuracy: 0.3060\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 1.4819 - accuracy: 0.4872 - val_loss: 2.1248 - val_accuracy: 0.3113\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 1.4653 - accuracy: 0.4882 - val_loss: 2.2171 - val_accuracy: 0.2800\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 1.4627 - accuracy: 0.4948 - val_loss: 2.0882 - val_accuracy: 0.3093\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4638 - accuracy: 0.4679 - val_loss: 2.2535 - val_accuracy: 0.2760\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.4360 - accuracy: 0.4867 - val_loss: 2.0287 - val_accuracy: 0.3247\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1.4271 - accuracy: 0.4895 - val_loss: 2.1006 - val_accuracy: 0.3093\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.4083 - accuracy: 0.4899 - val_loss: 1.9477 - val_accuracy: 0.3313\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 1.4157 - accuracy: 0.4893 - val_loss: 1.9894 - val_accuracy: 0.3353\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 1.3863 - accuracy: 0.4960 - val_loss: 2.2770 - val_accuracy: 0.2860\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 1.4009 - accuracy: 0.4821 - val_loss: 2.2801 - val_accuracy: 0.2887\n",
      "22/22 [==============================] - 1s 68ms/step - loss: 1.3811 - accuracy: 0.4894 - val_loss: 2.0090 - val_accuracy: 0.3360\n",
      "23/23 [==============================] - 1s 48ms/step - loss: 1.3903 - accuracy: 0.4899 - val_loss: 1.7159 - val_accuracy: 0.4033\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 1.3756 - accuracy: 0.4867 - val_loss: 1.6587 - val_accuracy: 0.4100\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 1.3791 - accuracy: 0.4913 - val_loss: 1.7488 - val_accuracy: 0.3967\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 1.3800 - accuracy: 0.4877 - val_loss: 1.7268 - val_accuracy: 0.4067\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 1.3800 - accuracy: 0.4857 - val_loss: 1.6024 - val_accuracy: 0.4293\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 1.3562 - accuracy: 0.4991 - val_loss: 1.6077 - val_accuracy: 0.4373\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 1.3505 - accuracy: 0.4901 - val_loss: 1.5059 - val_accuracy: 0.4680\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 1.3667 - accuracy: 0.4946 - val_loss: 1.5262 - val_accuracy: 0.4640\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 1.3634 - accuracy: 0.4892 - val_loss: 1.4990 - val_accuracy: 0.4727\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 1.3582 - accuracy: 0.5011 - val_loss: 1.4962 - val_accuracy: 0.4707\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 1.3510 - accuracy: 0.4975 - val_loss: 1.5973 - val_accuracy: 0.4473\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.3442 - accuracy: 0.4993 - val_loss: 1.4716 - val_accuracy: 0.4760\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.3492 - accuracy: 0.5047 - val_loss: 1.4276 - val_accuracy: 0.4967\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.3446 - accuracy: 0.5009 - val_loss: 1.4206 - val_accuracy: 0.4873\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3471 - accuracy: 0.4933 - val_loss: 1.4487 - val_accuracy: 0.4987\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.3323 - accuracy: 0.5045 - val_loss: 1.5992 - val_accuracy: 0.4580\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.3380 - accuracy: 0.5014 - val_loss: 1.4525 - val_accuracy: 0.4940\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.3337 - accuracy: 0.5093 - val_loss: 1.4088 - val_accuracy: 0.5007\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.3304 - accuracy: 0.5071 - val_loss: 1.4411 - val_accuracy: 0.4933\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 1.3097 - accuracy: 0.5182 - val_loss: 1.3963 - val_accuracy: 0.4993\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3354 - accuracy: 0.5104 - val_loss: 1.4538 - val_accuracy: 0.5007\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3165 - accuracy: 0.5129 - val_loss: 1.3956 - val_accuracy: 0.5120\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3275 - accuracy: 0.5102 - val_loss: 1.3815 - val_accuracy: 0.5107\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.3200 - accuracy: 0.5120 - val_loss: 1.3929 - val_accuracy: 0.5113\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 1.3223 - accuracy: 0.5200 - val_loss: 1.4023 - val_accuracy: 0.5067\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3088 - accuracy: 0.5192 - val_loss: 1.3989 - val_accuracy: 0.5053\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 1.3079 - accuracy: 0.5266 - val_loss: 1.4076 - val_accuracy: 0.5067\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 1.3117 - accuracy: 0.5170 - val_loss: 1.3565 - val_accuracy: 0.5240\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3051 - accuracy: 0.5180 - val_loss: 1.4445 - val_accuracy: 0.4920\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 1.3085 - accuracy: 0.5206 - val_loss: 1.3690 - val_accuracy: 0.5167\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 1.2926 - accuracy: 0.5176 - val_loss: 1.3852 - val_accuracy: 0.5113\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.2853 - accuracy: 0.5285 - val_loss: 1.3826 - val_accuracy: 0.5067\n",
      "27/27 [==============================] - 2s 71ms/step - loss: 1.2996 - accuracy: 0.5256 - val_loss: 1.3863 - val_accuracy: 0.5147\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.2707 - accuracy: 0.5335 - val_loss: 1.3974 - val_accuracy: 0.5147\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.2804 - accuracy: 0.5312 - val_loss: 1.4152 - val_accuracy: 0.5033\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.2631 - accuracy: 0.5386 - val_loss: 1.3503 - val_accuracy: 0.5200\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2686 - accuracy: 0.5304 - val_loss: 1.4199 - val_accuracy: 0.5067\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2740 - accuracy: 0.5368 - val_loss: 1.3863 - val_accuracy: 0.5093\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2692 - accuracy: 0.5413 - val_loss: 1.4592 - val_accuracy: 0.4960\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 1.2699 - accuracy: 0.5340 - val_loss: 1.3480 - val_accuracy: 0.5260\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 1.2533 - accuracy: 0.5482 - val_loss: 1.3524 - val_accuracy: 0.5207\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2475 - accuracy: 0.5448 - val_loss: 1.3470 - val_accuracy: 0.5273\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2434 - accuracy: 0.5456 - val_loss: 1.3310 - val_accuracy: 0.5320\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2480 - accuracy: 0.5432 - val_loss: 1.3702 - val_accuracy: 0.5087\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 1.2200 - accuracy: 0.5541 - val_loss: 1.3452 - val_accuracy: 0.5227\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2400 - accuracy: 0.5443 - val_loss: 1.3294 - val_accuracy: 0.5253\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 1.2251 - accuracy: 0.5498 - val_loss: 1.4269 - val_accuracy: 0.5027\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 1.2268 - accuracy: 0.5479 - val_loss: 1.3883 - val_accuracy: 0.5107\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 1.2283 - accuracy: 0.5573 - val_loss: 1.3692 - val_accuracy: 0.5053\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.2124 - accuracy: 0.5603 - val_loss: 1.3263 - val_accuracy: 0.5360\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.2061 - accuracy: 0.5598 - val_loss: 1.3892 - val_accuracy: 0.5147\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.2090 - accuracy: 0.5644 - val_loss: 1.3720 - val_accuracy: 0.5107\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1887 - accuracy: 0.5677 - val_loss: 1.3710 - val_accuracy: 0.5233\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.2086 - accuracy: 0.5632 - val_loss: 1.3162 - val_accuracy: 0.5393\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2068 - accuracy: 0.5685 - val_loss: 1.3596 - val_accuracy: 0.5167\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2020 - accuracy: 0.5622 - val_loss: 1.3167 - val_accuracy: 0.5427\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.1812 - accuracy: 0.5734 - val_loss: 1.3169 - val_accuracy: 0.5300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1992 - accuracy: 0.5631 - val_loss: 1.3451 - val_accuracy: 0.5313\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.1798 - accuracy: 0.5689 - val_loss: 1.3392 - val_accuracy: 0.5313\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1659 - accuracy: 0.5846 - val_loss: 1.3256 - val_accuracy: 0.5380\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1463 - accuracy: 0.5829 - val_loss: 1.3181 - val_accuracy: 0.5380\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1519 - accuracy: 0.5804 - val_loss: 1.3227 - val_accuracy: 0.5367\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 1.1697 - accuracy: 0.5768 - val_loss: 1.3256 - val_accuracy: 0.5380\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1597 - accuracy: 0.5783 - val_loss: 1.3150 - val_accuracy: 0.5407\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1405 - accuracy: 0.5876 - val_loss: 1.3321 - val_accuracy: 0.5320\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1476 - accuracy: 0.5859 - val_loss: 1.3252 - val_accuracy: 0.5373\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 1.1566 - accuracy: 0.5850 - val_loss: 1.3509 - val_accuracy: 0.5300\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1279 - accuracy: 0.5928 - val_loss: 1.3826 - val_accuracy: 0.5173\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1279 - accuracy: 0.5866 - val_loss: 1.3378 - val_accuracy: 0.5380\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1280 - accuracy: 0.5868 - val_loss: 1.3379 - val_accuracy: 0.5260\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1231 - accuracy: 0.5938 - val_loss: 1.4427 - val_accuracy: 0.5087\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1172 - accuracy: 0.5984 - val_loss: 1.3556 - val_accuracy: 0.5293\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1331 - accuracy: 0.5940 - val_loss: 1.3278 - val_accuracy: 0.5367\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.3150 - accuracy: 0.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:06<04:13, 126.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 239ms/step - loss: 2.9238 - accuracy: 0.0573 - val_loss: 3.0567 - val_accuracy: 0.1133\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 2.7717 - accuracy: 0.1093 - val_loss: 2.7393 - val_accuracy: 0.1187\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.5848 - accuracy: 0.1174 - val_loss: 2.8188 - val_accuracy: 0.0987\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2.4525 - accuracy: 0.1532 - val_loss: 3.2012 - val_accuracy: 0.0920\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 2.2464 - accuracy: 0.2085 - val_loss: 4.2278 - val_accuracy: 0.0933\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 2.0998 - accuracy: 0.2694 - val_loss: 5.8530 - val_accuracy: 0.0927\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.9240 - accuracy: 0.3524 - val_loss: 7.7152 - val_accuracy: 0.0927\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 1.7901 - accuracy: 0.3850 - val_loss: 8.0022 - val_accuracy: 0.0933\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 1.7029 - accuracy: 0.4243 - val_loss: 7.0441 - val_accuracy: 0.0953\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 1.6792 - accuracy: 0.4306 - val_loss: 5.9243 - val_accuracy: 0.0980\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.6283 - accuracy: 0.4556 - val_loss: 5.1556 - val_accuracy: 0.1053\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 1.5961 - accuracy: 0.4624 - val_loss: 3.2068 - val_accuracy: 0.1533\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 1.6043 - accuracy: 0.4717 - val_loss: 2.9375 - val_accuracy: 0.1707\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.5600 - accuracy: 0.4861 - val_loss: 2.6476 - val_accuracy: 0.2027\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 1.5769 - accuracy: 0.4735 - val_loss: 2.3020 - val_accuracy: 0.2600\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 1.5362 - accuracy: 0.4737 - val_loss: 2.1958 - val_accuracy: 0.2853\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 1.5101 - accuracy: 0.4829 - val_loss: 2.1743 - val_accuracy: 0.2900\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 1.4979 - accuracy: 0.4866 - val_loss: 2.0163 - val_accuracy: 0.3193\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 1.4759 - accuracy: 0.4803 - val_loss: 1.9807 - val_accuracy: 0.3193\n",
      "19/19 [==============================] - 1s 54ms/step - loss: 1.4701 - accuracy: 0.4856 - val_loss: 1.9125 - val_accuracy: 0.3320\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 1.4616 - accuracy: 0.4804 - val_loss: 1.7549 - val_accuracy: 0.3747\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 1.4380 - accuracy: 0.4838 - val_loss: 1.7037 - val_accuracy: 0.3940\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 1.4174 - accuracy: 0.4779 - val_loss: 1.6846 - val_accuracy: 0.4013\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.4122 - accuracy: 0.4857 - val_loss: 1.6918 - val_accuracy: 0.3987\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 1.3988 - accuracy: 0.4879 - val_loss: 1.7209 - val_accuracy: 0.3913\n",
      "22/22 [==============================] - 1s 49ms/step - loss: 1.4058 - accuracy: 0.4806 - val_loss: 1.6478 - val_accuracy: 0.4113\n",
      "22/22 [==============================] - 1s 48ms/step - loss: 1.3943 - accuracy: 0.4887 - val_loss: 1.6032 - val_accuracy: 0.4267\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 1.3879 - accuracy: 0.4904 - val_loss: 1.6437 - val_accuracy: 0.4140\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 1.3905 - accuracy: 0.4837 - val_loss: 1.6337 - val_accuracy: 0.4093\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 1.3729 - accuracy: 0.4931 - val_loss: 1.6058 - val_accuracy: 0.4167\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 1.3759 - accuracy: 0.4892 - val_loss: 1.5682 - val_accuracy: 0.4367\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 1.3876 - accuracy: 0.4861 - val_loss: 1.5539 - val_accuracy: 0.4460\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 1.3690 - accuracy: 0.4879 - val_loss: 1.5704 - val_accuracy: 0.4487\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 1.3832 - accuracy: 0.4886 - val_loss: 1.5474 - val_accuracy: 0.4487\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.3840 - accuracy: 0.4902 - val_loss: 1.4994 - val_accuracy: 0.4673\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.3575 - accuracy: 0.4860 - val_loss: 1.5252 - val_accuracy: 0.4560\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 1.3864 - accuracy: 0.4868 - val_loss: 1.5251 - val_accuracy: 0.4480\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 1.3753 - accuracy: 0.4865 - val_loss: 1.4987 - val_accuracy: 0.4613\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3567 - accuracy: 0.4896 - val_loss: 1.5601 - val_accuracy: 0.4520\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.3765 - accuracy: 0.4937 - val_loss: 1.4972 - val_accuracy: 0.4733\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3653 - accuracy: 0.4849 - val_loss: 1.4658 - val_accuracy: 0.4733\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.3444 - accuracy: 0.5023 - val_loss: 1.4844 - val_accuracy: 0.4593\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.3572 - accuracy: 0.5004 - val_loss: 1.5272 - val_accuracy: 0.4547\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3561 - accuracy: 0.5066 - val_loss: 1.4374 - val_accuracy: 0.4827\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3560 - accuracy: 0.5023 - val_loss: 1.4535 - val_accuracy: 0.4687\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.3432 - accuracy: 0.5023 - val_loss: 1.4322 - val_accuracy: 0.4820\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 1.3428 - accuracy: 0.5029 - val_loss: 1.4444 - val_accuracy: 0.4807\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3435 - accuracy: 0.4995 - val_loss: 1.4261 - val_accuracy: 0.4807\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3442 - accuracy: 0.5093 - val_loss: 1.4249 - val_accuracy: 0.4760\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 1.3222 - accuracy: 0.5037 - val_loss: 1.4127 - val_accuracy: 0.4853\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.3459 - accuracy: 0.5054 - val_loss: 1.4240 - val_accuracy: 0.4767\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3154 - accuracy: 0.5198 - val_loss: 1.3961 - val_accuracy: 0.4940\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 1.3267 - accuracy: 0.5139 - val_loss: 1.3986 - val_accuracy: 0.4767\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3245 - accuracy: 0.5116 - val_loss: 1.3668 - val_accuracy: 0.4967\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3002 - accuracy: 0.5206 - val_loss: 1.3734 - val_accuracy: 0.4953\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 1.3194 - accuracy: 0.5183 - val_loss: 1.3717 - val_accuracy: 0.4973\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.2990 - accuracy: 0.5260 - val_loss: 1.4436 - val_accuracy: 0.4793\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 1.3073 - accuracy: 0.5197 - val_loss: 1.4097 - val_accuracy: 0.4853\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.2900 - accuracy: 0.5371 - val_loss: 1.3752 - val_accuracy: 0.4960\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.2855 - accuracy: 0.5313 - val_loss: 1.5055 - val_accuracy: 0.4680\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 1.2884 - accuracy: 0.5331 - val_loss: 1.3601 - val_accuracy: 0.5080\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 1.2901 - accuracy: 0.5255 - val_loss: 1.3991 - val_accuracy: 0.4960\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 1.2890 - accuracy: 0.5316 - val_loss: 1.3804 - val_accuracy: 0.4980\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2710 - accuracy: 0.5399 - val_loss: 1.4744 - val_accuracy: 0.4740\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2847 - accuracy: 0.5329 - val_loss: 1.3427 - val_accuracy: 0.5053\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.2867 - accuracy: 0.5343 - val_loss: 1.5489 - val_accuracy: 0.4767\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2810 - accuracy: 0.5359 - val_loss: 1.3385 - val_accuracy: 0.5227\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2715 - accuracy: 0.5398 - val_loss: 1.4382 - val_accuracy: 0.4820\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2591 - accuracy: 0.5448 - val_loss: 1.3671 - val_accuracy: 0.4953\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2717 - accuracy: 0.5357 - val_loss: 1.4747 - val_accuracy: 0.4780\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2660 - accuracy: 0.5476 - val_loss: 1.3899 - val_accuracy: 0.4947\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2334 - accuracy: 0.5519 - val_loss: 1.3784 - val_accuracy: 0.5033\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 1.2448 - accuracy: 0.5448 - val_loss: 1.3332 - val_accuracy: 0.5133\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2304 - accuracy: 0.5553 - val_loss: 1.3231 - val_accuracy: 0.5120\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 1.2421 - accuracy: 0.5531 - val_loss: 1.3319 - val_accuracy: 0.5073\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2338 - accuracy: 0.5567 - val_loss: 1.3203 - val_accuracy: 0.5193\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2259 - accuracy: 0.5568 - val_loss: 1.3265 - val_accuracy: 0.5140\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2286 - accuracy: 0.5569 - val_loss: 1.3187 - val_accuracy: 0.5153\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2245 - accuracy: 0.5592 - val_loss: 1.3977 - val_accuracy: 0.4860\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2111 - accuracy: 0.5614 - val_loss: 1.3802 - val_accuracy: 0.4887\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2103 - accuracy: 0.5599 - val_loss: 1.3122 - val_accuracy: 0.5107\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.2113 - accuracy: 0.5590 - val_loss: 1.3481 - val_accuracy: 0.5047\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1967 - accuracy: 0.5678 - val_loss: 1.3596 - val_accuracy: 0.4980\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.1880 - accuracy: 0.5664 - val_loss: 1.3494 - val_accuracy: 0.5020\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1676 - accuracy: 0.5802 - val_loss: 1.3692 - val_accuracy: 0.5027\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1831 - accuracy: 0.5691 - val_loss: 1.3313 - val_accuracy: 0.5147\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1858 - accuracy: 0.5740 - val_loss: 1.3788 - val_accuracy: 0.5133\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1852 - accuracy: 0.5726 - val_loss: 1.3533 - val_accuracy: 0.5087\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1744 - accuracy: 0.5843 - val_loss: 1.3096 - val_accuracy: 0.5240\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1591 - accuracy: 0.5838 - val_loss: 1.3358 - val_accuracy: 0.5073\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1680 - accuracy: 0.5722 - val_loss: 1.3292 - val_accuracy: 0.5160\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1597 - accuracy: 0.5810 - val_loss: 1.3447 - val_accuracy: 0.5107\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1388 - accuracy: 0.5832 - val_loss: 1.3415 - val_accuracy: 0.5213\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.1289 - accuracy: 0.5917 - val_loss: 1.3472 - val_accuracy: 0.5160\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1392 - accuracy: 0.5894 - val_loss: 1.4582 - val_accuracy: 0.4867\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1361 - accuracy: 0.5884 - val_loss: 1.3866 - val_accuracy: 0.4940\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1404 - accuracy: 0.5839 - val_loss: 1.3323 - val_accuracy: 0.5160\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1276 - accuracy: 0.5917 - val_loss: 1.3572 - val_accuracy: 0.5073\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.1334 - accuracy: 0.5904 - val_loss: 1.3597 - val_accuracy: 0.5107\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1245 - accuracy: 0.5954 - val_loss: 1.5946 - val_accuracy: 0.4567\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5527 - accuracy: 0.4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [04:16<02:08, 128.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 193ms/step - loss: 2.9554 - accuracy: 0.0681 - val_loss: 3.8255 - val_accuracy: 0.1033\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 2.8899 - accuracy: 0.0806 - val_loss: 3.2055 - val_accuracy: 0.1040\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.6941 - accuracy: 0.1006 - val_loss: 3.0199 - val_accuracy: 0.1080\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2.4978 - accuracy: 0.1405 - val_loss: 2.9736 - val_accuracy: 0.1220\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 2.3247 - accuracy: 0.1897 - val_loss: 3.0961 - val_accuracy: 0.1400\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 2.1579 - accuracy: 0.2336 - val_loss: 3.2931 - val_accuracy: 0.1280\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 2.0072 - accuracy: 0.2890 - val_loss: 3.8733 - val_accuracy: 0.1147\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1.8646 - accuracy: 0.3596 - val_loss: 4.1995 - val_accuracy: 0.1153\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1.7391 - accuracy: 0.4143 - val_loss: 3.1734 - val_accuracy: 0.1540\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 1.6764 - accuracy: 0.4329 - val_loss: 2.4890 - val_accuracy: 0.2047\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.5997 - accuracy: 0.4532 - val_loss: 2.3763 - val_accuracy: 0.2307\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 1.5480 - accuracy: 0.4793 - val_loss: 2.3357 - val_accuracy: 0.2547\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 1.5543 - accuracy: 0.4774 - val_loss: 2.2995 - val_accuracy: 0.2640\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 1.5272 - accuracy: 0.4970 - val_loss: 2.2497 - val_accuracy: 0.2747\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 1.5474 - accuracy: 0.4839 - val_loss: 2.1689 - val_accuracy: 0.2900\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 1.5146 - accuracy: 0.4911 - val_loss: 2.1055 - val_accuracy: 0.3007\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 1.4833 - accuracy: 0.4959 - val_loss: 2.0104 - val_accuracy: 0.3227\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 1.4772 - accuracy: 0.4891 - val_loss: 1.9104 - val_accuracy: 0.3400\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 1.4824 - accuracy: 0.4798 - val_loss: 1.8949 - val_accuracy: 0.3487\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 1.4597 - accuracy: 0.4849 - val_loss: 1.7847 - val_accuracy: 0.3653\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 1.4416 - accuracy: 0.4865 - val_loss: 1.7187 - val_accuracy: 0.3793\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 1.4339 - accuracy: 0.4820 - val_loss: 1.6771 - val_accuracy: 0.4020\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 1.4371 - accuracy: 0.4765 - val_loss: 1.6519 - val_accuracy: 0.4093\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 1.4110 - accuracy: 0.4870 - val_loss: 1.6310 - val_accuracy: 0.4133\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 1.4137 - accuracy: 0.4712 - val_loss: 1.6309 - val_accuracy: 0.4160\n",
      "22/22 [==============================] - 1s 46ms/step - loss: 1.4073 - accuracy: 0.4817 - val_loss: 1.6138 - val_accuracy: 0.4213\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 1.3897 - accuracy: 0.4860 - val_loss: 1.5961 - val_accuracy: 0.4240\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 1.3907 - accuracy: 0.4841 - val_loss: 1.6066 - val_accuracy: 0.4160\n",
      "23/23 [==============================] - 1s 49ms/step - loss: 1.3773 - accuracy: 0.4936 - val_loss: 1.6672 - val_accuracy: 0.3980\n",
      "23/23 [==============================] - 1s 40ms/step - loss: 1.3762 - accuracy: 0.4879 - val_loss: 1.6339 - val_accuracy: 0.4087\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 1.3616 - accuracy: 0.4863 - val_loss: 1.5884 - val_accuracy: 0.4180\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 1.3559 - accuracy: 0.4974 - val_loss: 1.6268 - val_accuracy: 0.4173\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 1.3587 - accuracy: 0.4839 - val_loss: 1.5937 - val_accuracy: 0.4320\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 1.3475 - accuracy: 0.4949 - val_loss: 1.5981 - val_accuracy: 0.4367\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.3594 - accuracy: 0.4956 - val_loss: 1.6525 - val_accuracy: 0.4187\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 1.3641 - accuracy: 0.4934 - val_loss: 1.5824 - val_accuracy: 0.4367\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 1.3458 - accuracy: 0.4987 - val_loss: 1.5042 - val_accuracy: 0.4673\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 1.3616 - accuracy: 0.4926 - val_loss: 1.6383 - val_accuracy: 0.4213\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3436 - accuracy: 0.4985 - val_loss: 1.5497 - val_accuracy: 0.4440\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3599 - accuracy: 0.4964 - val_loss: 1.4449 - val_accuracy: 0.4907\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3516 - accuracy: 0.4946 - val_loss: 1.4383 - val_accuracy: 0.4733\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3475 - accuracy: 0.5003 - val_loss: 1.4353 - val_accuracy: 0.4747\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3489 - accuracy: 0.4890 - val_loss: 1.5932 - val_accuracy: 0.4473\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3449 - accuracy: 0.5027 - val_loss: 1.4642 - val_accuracy: 0.4833\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3437 - accuracy: 0.4969 - val_loss: 1.4169 - val_accuracy: 0.4840\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3305 - accuracy: 0.5070 - val_loss: 1.5087 - val_accuracy: 0.4593\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3287 - accuracy: 0.5079 - val_loss: 1.4354 - val_accuracy: 0.4840\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 1.3434 - accuracy: 0.4965 - val_loss: 1.4279 - val_accuracy: 0.4827\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 1.3272 - accuracy: 0.5135 - val_loss: 1.4808 - val_accuracy: 0.4700\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 1.3448 - accuracy: 0.5037 - val_loss: 1.3849 - val_accuracy: 0.5080\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.3210 - accuracy: 0.5131 - val_loss: 1.4036 - val_accuracy: 0.4840\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 1.3155 - accuracy: 0.5133 - val_loss: 1.4477 - val_accuracy: 0.4853\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 1.3193 - accuracy: 0.5173 - val_loss: 1.4723 - val_accuracy: 0.4680\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 1.3250 - accuracy: 0.5132 - val_loss: 1.4137 - val_accuracy: 0.4887\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 1.3127 - accuracy: 0.5231 - val_loss: 1.3688 - val_accuracy: 0.5033\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 1.3063 - accuracy: 0.5227 - val_loss: 1.4504 - val_accuracy: 0.4840\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 1.3053 - accuracy: 0.5249 - val_loss: 1.3756 - val_accuracy: 0.5047\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.3105 - accuracy: 0.5191 - val_loss: 1.3951 - val_accuracy: 0.5073\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 1.3026 - accuracy: 0.5250 - val_loss: 1.3832 - val_accuracy: 0.5007\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.2968 - accuracy: 0.5298 - val_loss: 1.3933 - val_accuracy: 0.5073\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 1.2809 - accuracy: 0.5289 - val_loss: 1.3502 - val_accuracy: 0.5227\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 1.2736 - accuracy: 0.5364 - val_loss: 1.3603 - val_accuracy: 0.5180\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 1.2920 - accuracy: 0.5276 - val_loss: 1.3667 - val_accuracy: 0.5133\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2830 - accuracy: 0.5363 - val_loss: 1.3808 - val_accuracy: 0.5173\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.2848 - accuracy: 0.5321 - val_loss: 1.4026 - val_accuracy: 0.5140\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 1.2715 - accuracy: 0.5366 - val_loss: 1.4093 - val_accuracy: 0.5100\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 1.2769 - accuracy: 0.5340 - val_loss: 1.4485 - val_accuracy: 0.4913\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2632 - accuracy: 0.5436 - val_loss: 1.3498 - val_accuracy: 0.5333\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.2553 - accuracy: 0.5402 - val_loss: 1.3677 - val_accuracy: 0.5093\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 1.2590 - accuracy: 0.5413 - val_loss: 1.3385 - val_accuracy: 0.5187\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 1.2448 - accuracy: 0.5501 - val_loss: 1.3553 - val_accuracy: 0.5193\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2477 - accuracy: 0.5469 - val_loss: 1.4202 - val_accuracy: 0.4993\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 1.2483 - accuracy: 0.5425 - val_loss: 1.3296 - val_accuracy: 0.5387\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 1.2370 - accuracy: 0.5556 - val_loss: 1.3479 - val_accuracy: 0.5193\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2396 - accuracy: 0.5529 - val_loss: 1.3229 - val_accuracy: 0.5273\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 1.2219 - accuracy: 0.5555 - val_loss: 1.3567 - val_accuracy: 0.5213\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.2275 - accuracy: 0.5525 - val_loss: 1.3483 - val_accuracy: 0.5340\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 1.2149 - accuracy: 0.5608 - val_loss: 1.3898 - val_accuracy: 0.5167\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 1.2090 - accuracy: 0.5655 - val_loss: 1.3752 - val_accuracy: 0.5227\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.2056 - accuracy: 0.5708 - val_loss: 1.3196 - val_accuracy: 0.5360\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1988 - accuracy: 0.5669 - val_loss: 1.4706 - val_accuracy: 0.4947\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1963 - accuracy: 0.5711 - val_loss: 1.3220 - val_accuracy: 0.5347\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.1780 - accuracy: 0.5734 - val_loss: 1.3338 - val_accuracy: 0.5313\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 1.1946 - accuracy: 0.5654 - val_loss: 1.3443 - val_accuracy: 0.5340\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1817 - accuracy: 0.5775 - val_loss: 1.3572 - val_accuracy: 0.5253\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1826 - accuracy: 0.5628 - val_loss: 1.3379 - val_accuracy: 0.5327\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.1795 - accuracy: 0.5766 - val_loss: 1.3455 - val_accuracy: 0.5280\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1818 - accuracy: 0.5725 - val_loss: 1.3271 - val_accuracy: 0.5387\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1763 - accuracy: 0.5743 - val_loss: 1.3092 - val_accuracy: 0.5367\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1609 - accuracy: 0.5815 - val_loss: 1.3313 - val_accuracy: 0.5233\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1645 - accuracy: 0.5781 - val_loss: 1.3131 - val_accuracy: 0.5413\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 1.1411 - accuracy: 0.5848 - val_loss: 1.3277 - val_accuracy: 0.5313\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.1414 - accuracy: 0.5870 - val_loss: 1.3362 - val_accuracy: 0.5333\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.1464 - accuracy: 0.5884 - val_loss: 1.3510 - val_accuracy: 0.5340\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 1.1312 - accuracy: 0.5900 - val_loss: 1.3457 - val_accuracy: 0.5347\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.1265 - accuracy: 0.5894 - val_loss: 1.3602 - val_accuracy: 0.5260\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.1232 - accuracy: 0.5954 - val_loss: 1.3280 - val_accuracy: 0.5387\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1277 - accuracy: 0.5952 - val_loss: 1.3201 - val_accuracy: 0.5360\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1166 - accuracy: 0.5955 - val_loss: 1.3379 - val_accuracy: 0.5413\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 1.1262 - accuracy: 0.5901 - val_loss: 1.4690 - val_accuracy: 0.4973\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4489 - accuracy: 0.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:28<00:00, 129.43s/it]\n"
     ]
    }
   ],
   "source": [
    "for test_model in test_models:\n",
    "    print(test_model)\n",
    "    model_scores = []\n",
    "\n",
    "    for _ in tqdm(range(N_TRIALS)):\n",
    "        model = ClassifierModel(output_shape=10, **models_hyperparameters[test_model])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "        \n",
    "        for i in range(N_EPOCHS):\n",
    "            n_samples = int(np.tanh(2 * (i + 1)/ (N_EPOCHS / 2)) * train_size)\n",
    "            samples_ids = order_assessment[:n_samples]\n",
    "            \n",
    "            model.fit(\n",
    "                x_train[samples_ids], y_train[samples_ids], \n",
    "                validation_data=(x_val, y_val),\n",
    "                epochs=1, batch_size=BATCH_SIZE,\n",
    "                verbose=1, callbacks=[early_stopping]\n",
    "            )\n",
    "        \n",
    "        _, accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "        \n",
    "        model_scores.append(accuracy)\n",
    "    \n",
    "    results[test_model] = model_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:42:47.674616Z",
     "start_time": "2024-02-20T17:36:19.267900Z"
    }
   },
   "id": "ce9112b33b1ada44"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "{'test_model_1': [0.5246666669845581, 0.4620000123977661, 0.4846666753292084]}"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:42:47.689677Z",
     "start_time": "2024-02-20T17:42:47.635269Z"
    }
   },
   "id": "909e15d33e1ab350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{'test_model_1': [0.5386666655540466, 0.5506666898727417, 0.5633333325386047]}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786f28960764af5d"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9647273193205547"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.tanh(2 * (200 + 1)/ N_EPOCHS))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:22:53.653399Z",
     "start_time": "2024-02-20T17:22:53.643595Z"
    }
   },
   "id": "9790fd22bda8078b"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7698665359089003"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.tanh(2 * (50 + 1)/ (N_EPOCHS / 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:23:55.805922Z",
     "start_time": "2024-02-20T17:23:55.800596Z"
    }
   },
   "id": "156a0684f1bb544b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48f13aeabc23da41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
