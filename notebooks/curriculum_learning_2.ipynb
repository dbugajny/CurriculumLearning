{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:35:30.523328Z",
     "start_time": "2024-04-27T18:35:30.519824Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from curriculum_learning.models.classifier_model import ClassifierModel\n",
    "from curriculum_learning import utils\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "with open(\"models_hyperparameters.yaml\", \"r\") as stream:\n",
    "    models_hyperparameters = yaml.safe_load(stream)\n",
    "    \n",
    "with open(\"config_tests.yaml\", \"r\") as stream:\n",
    "    config_tests = yaml.safe_load(stream)\n",
    "    \n",
    "N_EPOCHS = 50\n",
    "N_TRIALS = 10\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "CONFIG = config_tests[\"proba_best\"]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:45:09.158517Z",
     "start_time": "2024-04-27T20:45:09.150571Z"
    }
   },
   "id": "fa5a1f60ac32c234"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 20:32:32.784355: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-27 20:32:33.578237: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ds_1 = tfds.load(\"stl10\", split=\"train\", as_supervised=True, shuffle_files=False)\n",
    "ds_2 = tfds.load(\"stl10\", split=\"test\", as_supervised=True, shuffle_files=False)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for x_, y_ in ds_1.as_numpy_iterator():\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "for x_, y_ in ds_2.as_numpy_iterator():\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "    \n",
    "x = np.array(x, dtype=np.float32) / 255\n",
    "y = np.array(y, dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:32:33.786671Z",
     "start_time": "2024-04-27T18:32:32.164873Z"
    }
   },
   "id": "833df77eba9d27a2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(9100, 1950, 1950)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "train_size = x_train.shape[0]\n",
    "train_size, len(x_val), len(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:32:33.982522Z",
     "start_time": "2024-04-27T18:32:33.787713Z"
    }
   },
   "id": "8424e92d91deb0ac"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "x_train_sorted = x_train[np.argsort(y_train)]\n",
    "y_train_sorted = y_train[np.argsort(y_train)]\n",
    "_, counts = np.unique(y_train_sorted, return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:38:29.002825Z",
     "start_time": "2024-04-27T18:38:28.759491Z"
    }
   },
   "id": "a2cd5df2d1ace314"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ClassifierModel(output_shape=n_classes, **models_hyperparameters[\"test_model\"])\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
    "model(x_train[0:1])\n",
    "# model.save_weights(\"../models/default_model.weights.h5\")\n",
    "model.load_weights(\"../models/default_model.weights.h5\")\n",
    "model_weights = model.get_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T18:35:58.290458Z",
     "start_time": "2024-04-27T18:35:58.106616Z"
    }
   },
   "id": "5d8c20ae81a03a89",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model_scores \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      2\u001B[0m verbose \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 3\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, start_from_epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(N_TRIALS)):\n\u001B[1;32m      6\u001B[0m     model\u001B[38;5;241m.\u001B[39mset_weights(model_weights)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model_scores = []\n",
    "verbose = 0\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=0)\n",
    "\n",
    "for _ in tqdm(range(N_TRIALS)):\n",
    "    model.set_weights(model_weights)\n",
    "    \n",
    "    for j in range(len(model.layers[:-1])):\n",
    "        model.layers[j].layers[-1].rate = 0.25\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        n_samples = int(np.tanh(2 * (i + 1) / N_EPOCHS) * train_size)\n",
    "        \n",
    "        samples_proba = utils.calculate_proba(\n",
    "            model, x_train_sorted, y_train_sorted, counts\n",
    "        )\n",
    "        \n",
    "        samples_ids = utils.chose_samples(n_samples, samples_proba, CONFIG[\"order_type\"])\n",
    "        model.fit(\n",
    "            x_train_sorted[samples_ids],\n",
    "            y_train_sorted[samples_ids],\n",
    "            # validation_data=(x_val, y_val),\n",
    "            epochs=1,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        for j in range(len(model.layers[:-1])):\n",
    "            model.layers[j].layers[-1].rate -= 0.003\n",
    "    \n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=500, batch_size=BATCH_SIZE, callbacks=[early_stopping], verbose=verbose)\n",
    "            \n",
    "    _, accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=verbose)\n",
    "    model_scores.append(accuracy)\n",
    "    print(\"Mean:\", np.mean(model_scores), \" Median: \", np.median(model_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:59:01.373346Z",
     "start_time": "2024-04-27T20:59:01.160228Z"
    }
   },
   "id": "ce9112b33b1ada44"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:42<06:18, 42.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5189743638038635  Median:  0.5189743638038635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:13<04:48, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4933333396911621  Median:  0.4933333396911621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:49<04:11, 35.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.49914530913035077  Median:  0.510769248008728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:21<03:26, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4887179583311081  Median:  0.48923078179359436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:53<02:47, 33.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4722051382064819  Median:  0.4676923155784607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:25<02:11, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.47324787080287933  Median:  0.4730769246816635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:57<01:38, 32.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4729670413902828  Median:  0.47128206491470337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [04:30<01:05, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4671794958412647  Median:  0.46948719024658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [05:04<00:33, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4665527145067851  Median:  0.4676923155784607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:37<00:00, 33.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4645641088485718  Median:  0.4646153897047043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_scores_random = []\n",
    "verbose = 0\n",
    "early_stopping_random = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=5, start_from_epoch=35)\n",
    "\n",
    "for _ in tqdm(range(N_TRIALS)):\n",
    "    model.set_weights(model_weights)\n",
    "\n",
    "    for j in range(len(model.layers[:-1])):\n",
    "        model.layers[j].layers[-1].rate = 0.3\n",
    "\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=500, batch_size=BATCH_SIZE, verbose=verbose, callbacks=[early_stopping_random])\n",
    "\n",
    "    _, accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=verbose)\n",
    "    model_scores_random.append(accuracy)\n",
    "    print(\"Mean:\", np.mean(model_scores_random), \" Median: \", np.median(model_scores_random))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:34:52.560619Z",
     "start_time": "2024-04-27T20:29:14.968218Z"
    }
   },
   "id": "42a40bf5388b5d36",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[0.519487202167511,\n 0.47846153378486633,\n 0.508717954158783,\n 0.4558974504470825,\n 0.45384615659713745]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores_random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T19:05:51.662015Z",
     "start_time": "2024-04-27T19:05:51.656748Z"
    }
   },
   "id": "e075c49123dbac18",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5317948818206787, 0.48328205943107605)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model_scores), np.mean(model_scores_random)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T19:06:10.986533Z",
     "start_time": "2024-04-27T19:06:10.983294Z"
    }
   },
   "id": "eaca2b851bbe38ec",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbugajny/PycharmProjects/CurriculumLearning/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/dbugajny/PycharmProjects/CurriculumLearning/venv/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(nan, nan)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sorted(model_scores)[5:]), np.mean(sorted(model_scores_random)[5:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T19:05:53.481882Z",
     "start_time": "2024-04-27T19:05:53.474275Z"
    }
   },
   "id": "48c22b8b34aed2bf",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TtestResult(statistic=3.476015034822166, pvalue=0.008368460131238117, df=8.0)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "scipy.stats.ttest_ind(model_scores, model_scores_random)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T19:06:13.039164Z",
     "start_time": "2024-04-27T19:06:13.031281Z"
    }
   },
   "id": "a3c5ef08d6e5bf5e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab854c56fbbb8a3d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
